#+LATEX_CLASS: article
#+TITLE: Gauge Security Development Automation
#+AUTHOR: Michael Mattie

#+LATEX: \pagebreak

* Introduction

What school teaches is how to write code. What experience as a paid
professional developer teaches you is how to build business assets.

Business assets go beyond code to include API's, integrations,
teams, and releases.

Just because you can write a binary search doesn't mean you know about
merging, building, releasing, devops, maintenance, and operations -
how to deliver large and small.

In fact many students come out of school only knowing how to write
homework, not how to integrate into a team building business assets
on a deadline.

New programmers think unit tests are their safety net until they hit a
wall on merging, integration, release, devops, and operations.

The truth is that devops was invented because the tools of the trade
have become so complex that they warrant a position of their own.

At Gauge Security we have experienced these issues and grown up in
Disney, Comcast, Oracle, and Amazon. We have seen the failures in
other companies.

In all these organizations developers huddled around their limited
knowledge of tools, like a swimmer clinging to a life vest. Instead of
solving issues with tools, the tools were the issue, day in and day
out.

Starting in 2020 I tried to sort out this mess with automation. It
started as a Makefile, then a bash script called manage.sh, and finally
PythonSh. The idea was to build correct tool use into a single command,
with intelligence to tailor it to a context and scenario.

You are going to see the result of 20+ years of experience, and 4 years
of baking into a mature, effective, and innovative tool.

Let's get started!

#+LATEX: \pagebreak

* Gauge Security (PythonSh) - Automation is Innovation.

I have extensive experience in professional and personal projects with
Python. From that experience clearly one of the most poorly thought
out and vexing aspects of coding is just getting the code to
run.

Getting it to run on one developer's machine is just the beginning,
making it portable to other developers is another hurdle. And finally
building a good release to the end users is yet another hurdle.

Throughout the process version control: especially with git is often
a massive time-sink in trying to fix broken repos and branches. Programmers
are made timid by their lack of understanding and their frustrations and
use it and never move beyond the most basic commands.

Not knowing how to handle packages effectively leads to monolithic repos,
where the inexperience with git, and a fear of merging leads to clumsy
collisions, and losses in time, code, and lengthy git debugging sessions.

Pythonsh is a path forward for python development: combining effective
use of git, python, packages, and multiple repositories. Pythonsh is
the way out of the development wilderness.

* Development Problems

** The plethora of tools

A developer typically uses language tools, IDE tools, version control
tools, artifact repositories, and dependency managers. All these tools
are used without any integration into a cohesive tool-chain.

- Running code is fragmented process due to the use of either plain
  system interpreters, tox for multiple python versions, or pyenv for
  isolated virtual environment environments. Developers are often
  unaware of the different strengths and weaknesses of the tools and
  just copy the first thing they find on the internet.

- Python has many different versions, and each milestone introduces
  new features that code can become dependent on. Installation can be
  by a OS package, Open Source package managers like homebrew, or
  virtual environment interpreters like pyenv. This fragmentation
  leads to chaos with developers often not having a firm grasp on
  what python their code is actually running on.

- Many times - without good version control practices, or artifact
  repositories - the sharing of code can be as bad as cut and paste or
  sending files over slack.

- Backwards compatibility is an assumption with no explicit guarantee.
  Practices for maintaining release metadata that allow a release to
  be rebuilt from a given source version, interpreter, and module
  environment are not even considered much less implemented.

- The python build system is frankly a disaster. It is both layered
  and fragmented with the latest standards encouraging this dumpster
  fire instead of putting the flames out. Itâ€™s origins are setuptools
  with an executable config and an outdated egg format.

- Basic best practices such as the storage and use of secrets is
  anarchy. Developers still fequently put credentials in the
  code. (my utilities repo: wallet handles this)

** The Tool Tax

Modern code is built with so many tools touted as giving this or that
advantage to the developer, that the developer is taxed in time,
learning, and management by every tool.

I call this the "Tool Tax". What usually falls out from the vast array
of tools is that the developer skims 10% of the tools capability, but
does not know how to use, not use, or fix any of it.

Mostly the developer tries to survive off blogs and stack overflow
searching by their task for solutions, but often just digging the hole
deeper, and deeper.

** Automation

What then is the answer to these dilemna ? The answer is automation.
Automation has three key benefits:

- speed: the pace of development is greatly accelerated by automation.
- utilization: with automation ten commands becomes one. This means that
  the full capabilities of the tools are realized.
- correctness: the right way, the way to avoid mistakes, is baked into
  the automation. Development becomes reliable and routine in the tool
  aspect.

Pythonsh commands are mostly single commands that accomplish the entire
task by automation.

For example the "ahead" command shows what changes have been made that
are not in the trunk. Even if a developer has known how to invoke git
to do this, he may fumble or look it up. With PythonSh a single
command detects the structure of the repo and constructs the git
command for the developer without any arguments.

There are dozens of commands with this kind of intelligence built-in.
The commands have also been debugged over years of use in a wide range
of repositories.

Fast,reliable, and powerful are the three prongs of automation.

** Multiple repositories

Often times developers get crowded into a single monolothic repository
because the construction of a new repo and it's devops tool-chain is
magical, and laborious.

They collide frequently leading developers to "section off" their
files and avoid merging. When the inevitable implict merge occurs at
build there is a frantic late-night integration sessions and working
Saturdays to get the build done by Monday.

A better approach is to break the project down into components,
components into repositories, an integrate back together with
packages. Each repository or package is released on it's own
cadence and the result is stability and smooth integration.

Due to the magical nature of devops however, teams still
crowd into whatever repository has a working tool-chain.

PythonSh can spin up a repository and tool-chain in under five
minutes allowing code to be replicated, distributed, and built
built in a modular fashion.

** Mistakes

The big mistake is to think that these tool and repository hygenic
tasks are chrome on a semi-truck, a litte flashy but not essential to
get down the road.

Its only when the project goes to build and things go sideways on a
Friday night, and everyone is calling their family to tell them not to
wait up, that the importance of the tool-chain and the development
practices starts to cut deep.

Pythonsh deals with the Tool Tax upfront, and delivers speed,
efficiency, and reliable progress from start to finish.

Let's get into some details!

* Workflows

Worflows are the process the team uses to deliver. In the end
it is always about delivery.

The right process delivers on-time, and as promised. The wrong
work-flow blames everything except the developer for delays, bugs, and
failures.

Workflow comes in two parts

- Version Control Workflow
- Build Workflow

** Multiple Repositories

Strategically it is vital to move developers into their own
repositories for these workflows to be effective. Each component
should develop and release as fast as they can bake, not every
developer tripping over everyone else in a shared repository.

To do this right you need a Version Control Workflow, and a Build
Workflow.

** Version Control Workflow

Version Control is the ultimate workflow for the developer. There
is a near universal convergance on git as the version control system.

Git was developed as a implementation strata, and interfaces called
porcelins. Despite improving user interfaces developers still lack
understanding of core concepts like merging, and often times you are
back to the command line, like it or not.

There is also no workflow defined by git, so it's the wild west
unless a process is defined. Let's look closer:

There are two basic variations on workflows.

- develop on trunk, branch for release
- develop on branch, merge to trunk which is stable.

*** Develop on Trunk

Many projects do development on the trunk and branch for release.
each developer, often at best is on a branch. This makes for painful
merging, usually late in the game, and developers do not have an
opportunity to merge incrementally.

*** Develop on a branch

The alternative is to develop on a branch, but without a development
trunk each developer ends up on "forever" branches, merging with great
difficulty.

*** Git Flow

Git Flow is a workflow supported by reliable and intuitive
tooling. [[cite:&flow]]

In git flow all of the shared development is on "develop" and
developers work in isolated branches.

The developers all merge their work into development, and can
constantly and incrementally pull from develop, merging on-the-go so
that a huge mess to untangle isn't created.

That is develop, and feature branches. Releases are on main/master
merging the work from develop once develop has stabalized. When
There are releases they are tagged and every release can be
easily re-constructed.

** Build Workflow

The correct way to integrate is by packages. Developers should not
try and sync and push and pull each other into integrations that
are half-baked.

Each repository releases when it is fully baked, and integration
is by well defined API's instead of fragile ad-hoc source
level interfaces.

It's vital to have a shared artifact repository, a simple way to
build, and well tested packages to integrate.

PythonSh accomplishes this by setting up virtual environments for
dependency isolation, building, testing, and releasing.

* Introducting PythonSh


pythonsh has a script pysh-install.sh that
when called with:

- private = my personal ssh checkout for development
- public  = https checkout for client consumption

This script will install a git submodule pythonsh and create a symlink
to py.sh for the CLI interface.

from there all commands are in the form:

#+BEGIN_SRC bash
./py.sh tools-unix
#+END_SRC

Most commands are a single command, few take arguments. They
ccomplish a task with as much intelligence as possible so
arguments don't have to be a stumbling block, and it
speeds things up.

** Project Creation

Pythonsh needs to install virtualenv for the user. To
solve the chicken-and-egg problem PythonSh is cloned
first:


#+BEGIN_SRC bash
apt install git git-flow

cd code
curl <pythonsh> pysh-install.sh

./pysh-install.sh public
cd pythonsh

./py.sh tools-unix
#+END_SRC

Here we install git, and git-flow. Then we clone the pythonsh
repository. 

Inside pythonsh we run "tools-unix" which installs pyenv from git
source into $HOME/.pyenv


#+BEGIN_SRC bash
./py.sh tools-zshrc
./py.sh tools-custom
./py.sh tools-prompt
#+END_SRC

These tools commands setup the developer's shell for pythonsh.  Its a
toolbox with numerous functions. the "tools-zshrc" command is
required, along with use of the zsh shell.

"tools-custom" sets up an environment autodetecting many key things
such as paths, ssh-agent, and the EDITOR.

At this point pyhtonsh has completed global setup. Here is what
creating a repository looks like


#+BEGIN_SRC bash
mkdir project
cd project

git init
git flow init

./pysh-install.sh public

,# this checks out any other sub-modules
git submodule init
git submodule update --init
#+END_SRC

This is all that is needed to setup a project. pythonsh is ready to
use for best practices. This is what a prompt looks like:

#+BEGIN_SRC bash
<work> [system] pythonsh:develop(*+) ->
#+END_SRC

- work is the system name so you dont get confused when remoting into other systems
- system is the virtualenv which is not activated in this case.
- pythonsh is the repository you are at.
- develop is the current branch
- () encloses * and + , where * = dirty, and + = staged changes

** Project Configuration

The idea of the python.sh file is that it contains all the information
needed to drive the tool-chain. It contains version information and
the names for things.

#+BEGIN_SRC bash
,# pythonsh configuration file
VERSION=0.15.0

PACKAGES=pyutils
SOURCE=.

BUILD_NAME=pythonsh

DOCKER_VERSION="0.1.0"

VIRTUAL_PREFIX='pythonsh'
PYTHON_VERSION='3.12'
#+END_SRC

We will circle back later on this file, but the important thing to
know is that this is the "Source of Truth" for the tool-chain and as
much as possible all other files needed for python are generated from
this configuation.

** Source Configuration

Setting up the source requires one key thing from python.sh:
the directory containing the source.

#+BEGIN_SRC bash
,# pythonsh configuration file
SOURCE=src
VIRTUAL_PREFIX='pythonsh'
PYTHON_VERSION='3.12'
#+END_SRC

** Python configuration

#+BEGIN_SRC bash
./py.sh project-virtual
#+END_SRC

This is where the intelligence starts. This command does:

- deactivates any pre-exising source environment
- finds the latest "dot" release of the specified python version.
- compiles a new python interpreter if needed.
- installs the "dev" and "test" virtual environments.

At this point the developer would type:

#+BEGIN_SRC bash
switch_dev
#+END_SRC

which would activate the virtual environment for python, a
dependency isolated environment for development, without
any extraneous packages the developer might have on his
system.

The next step is to bootstrap.

** PythonSh bootstrap

A virtual environment doesnt have packages that pythonsh itself
needs, nor does it have pipenv for package management, or
development tools.

Bootstrap initializes the virtual environment and does so in three
stages. All of boostrap is fully automatic.

- ugprade pip
- install pipenv
- install dependencies for pythonsh
- search the source tree for Pipfile fragments, merge into a root Pipfile
- install the dependencies of the repository.
- search installed packages as well as sources for Pipfile fragments
- make a second merged Pipfile with source and package Pipfile fragments
- install combined dependencies.

The merging process sorts through all the dependencies in source and
packages managed by PythonSh. It takes the higher version of every
version comparison and generates a root Pipfile.

Some would say this is imperfect: that only PythonSh packages can be
merged - which is true. But by synchronizing versions at teir-1 and
tier-2 the problems with package version issues are massively reduced,
and more manageable. Often pendantic hand wringing is a obstacle to
making practical solutions.

** Integrating Source into the virtualenv

There are a couple of ways to insert the source into the python virtualenv.
The first is with an editable package, the common way. A second way is
to put a .pth file into site-packages.

I prefer the uncommon .pth file approach since it is more flexible, and
I will usually prefer flexiblity over dogma.

#+BEGIN_SRC bash
./py.sh add-src
#+END_SRC

This installs a .pth file from python.paths, a file in the repository.
Both absolute and relative paths are accepted.

#+BEGIN_SRC bash
show-paths = list .pth source paths
add-paths  = install .pth source paths into the python environment
rm-paths   = remove .pth source paths
site       = print out the path to site-packages
#+END_SRC

- show-paths: shows all the paths in the virtual environment
- add-paths: installs a pth file generated from python.paths in the repo root
- rm-paths: removes the .pth file
- site: prints out the virtualenv site-packages directory location

The next step is to get the source code into the virtualenv.
There is a way to make it possible by using "editable" packages,
however I prefer a second approach. It is possible to put ".pth"
packages into site-packages in the virtual environment.

** PythonSh Starter Kit

Here is a template for starting a PythonSh repository. The code is in
scripts/starter-kit.sh

#+BEGIN_SRC bash :shebang "#! /usr/bin/env bash" :tangle "scripts/starter-kit.sh"
REPO=$1
CLONE=$2
BRANCH=$3

git clone $REPO $CLONE
cd $CLONE

,# setup git flow
git flow init

,# install pythonsh
test -d pythonsh || $HOME/code/pysh-install.sh public

,# this checks out any other sub-modules
git submodule init
git submodule update --init

,# create the virtual environments
 ./py.sh project-virtual

,# install source shims
./py.sh add-paths

,# boostrap virtualenv
./py.sh bootstrap

,# start from develop
git checkout develop

,# start the feature branch
git flow feature start $BRANCH
#+END_SRC

This is a complete developer environment and devops toolchain in less
than five minutes.

* Version Control Workflow

The version control workflow is the most difficult part for
developers to master due to the frequent need to understand
complex history graphs, and arcane commands.

Usually there are only loose practices around commits, and
it makes it impossible to "look over the shoulder" and
understand what is going on in the repository.

** Version Control Conventions

It is vital for the tools, and for the developers to adhere to
conventions in commits, tags, and releases. How can another developer
understand your history if your commit messages are: "fixed some bugs"?

** Conventional Commits and Reports

Conventional commits [[cite:&conventional]] is a standard for semantics
and formatting of commits. I use it as a starting point, and add a
couple such as refactor, and sync.

#+BEGIN_SRC bash
(feat) add a new dialog for listing reports
#+END_SRC

These conventions are crucial since it makes it clear to developers
what a commit consists of, and allows tools to process the history in
powerful ways.

To really understand the power of conventional commits you have
to consider the tooling. What if it was possible to generate
release notes entirely from commits ? Pythonsh does!

This is what a history looks like, a jungle of different types of commits:

#+BEGIN_SRC bash
(sync) [2024-03-16T08:16:03-07:00] syncd: pythonsh
04fb73e Merge branch 'release/0.10.0' into develop
8f13b6b (sync) [2024-03-15T22:35:36-07:00] syncd: pythonsh
776971e (release) release 0.10.0 many fixes to dwim, support for org mode etc..
dbd926b (fix) insert the commit type as well as the message and report
1ad304d (fix) report no longer takes a message argument so insert the message ourselves
c6f8a67 (sync) [2024-03-15T22:14:20-07:00] syncd: pythonsh
0fbf0df (feat) create a insert-syncd command that generates a sync commit message
fd93322 (sync) 3-15-2024 sync pythonsh
b8b069a (fix) make m keybinding be menu and remove a
420f003 (feat) functionalize the helm frame configuration
7bea9b9 (sync) 3-15-2024 sync latest citeproc,helm, and helm-bibtext
ec46225 (fix) add ignore=dirty to helm-frame
#+END_SRC

This is what a report looks like. It groups the commits by type and
is injectable into a commit. This allows for editing the report
into release notes in the commit.

Without release notes it's only tribal knowledge what is in a release
or not. Professionals do not leave history up to word of mouth. Take
a look at a report and see how easy it is to edit into release notes.

#+BEGIN_SRC bash
devil> [system] grail:develop(*) -> ./py.sh status-report

,* features

(feat) through questions determine what type of report to insert
(feat) create a insert-syncd command that generates a sync commit message
(feat) show the branch on the modeline
(feat) add a bunch of fonts and a install script for macos
(feat) add a tramp command that opens dired on the host home directory
(feat) revamp the scripts to build emacs from brew and deal with byte copmilation

,* fixes

(fix) insert the commit type as well as the message and report
(fix) report no longer takes a message argument so insert the message ourselves
(fix) make m keybinding be menu and remove a
(fix) add ignore=dirty to helm-frame
(fix) fix the battery with a closing >
(fix) remove initial bib file which is obsoleted by compsci repo now
(fix) disable helm-frame for now

,* syncs

(sync) [2024-03-16T08:16:03-07:00] syncd: pythonsh
(sync) [2024-03-15T22:35:36-07:00] syncd: pythonsh
(sync) [2024-03-15T22:14:20-07:00] syncd: pythonsh
(sync) 3-15-2024 sync latest citeproc,helm, and helm-bibtext
(sync) ff pythonsh to 3-15-2024
(sync) sync helm core 3-15-2024

,* refactor

(refactor) clean up formatting so it's easier to read
(refactor) cleanup formatting
(refactor) pull all the scripts and files for emacs from pythonsh and combine into compile-emacs.sh
(refactor) refactor out mattie references and fix scheme repl auto start
(refactor) minor whitespace changes
(refactor) clean up lex-cache and check dwim-complete
<devil> [system] grail:develop(*) -> 
#+END_SRC

Here are my prefixes which extend the conventional commit standard:

- (feat) new features. A oneliner is either sufficient or some prose is added below
  the main commit line.
- (fix) this is primarily for development. They belong on feature branches.
  fixes are corrections to code that has not been released yet.
- (bug) bugs are defects in code that has been released. They need to be
  included in the release notes
- (issue) issues are bugs that have been reported by users and have a ticket assigned.
- (sync) a fast-forward. This is done only on the trunks: develop and main where they
  are histories that are stable, and consist entirely of merges.
 
  The other use case is for third party submodules. since .gitmodules and git internals
  remember the commit sync'd its not a good idea to introduce local commits. That will
  get ugly.

  For (sync) is is critical that the date be in the one-liner as dependencies are
  being updated and this has a large impact on the release.

- (pull) for working on feature branches, pull is for pulling changes into the
  feature branches
- (merge) merge is for merging developer work into the shared development trunk.
- (release) releases are alpha and beta releases. The actual release process with
  git flow release start is more complex and is documented below
- (alpha) both tag and possibly a commit this indicates it's a beta candidate
  and the developer wants to tag/commit to establish a baseline
- (beta) This is on the develop trunk and indicates that this is a point from
  which beta_fix and beta_<feature branch> should be branched off this point.
- (refactor) a change to make development or maintenance easier that has no impact on functionality
- (doc) documentation updates.

This systematic annotating of the history makes it possible to
understand the changes far beyond cryptic and poor commit messsages.

This also allows for tools that help insert commit messages, and
generate entire release notes into merge commits and the like.

#+BEGIN_SRC bash
./py.sh status-report
./py.sh release-report
#+END_SRC

Status report shows all the developers changes grouped by type
that are outstanding from the development trunk.

The release-report shows all the work in the development trunk
outstanding since the last release. With tag, branching, and
commit conventions this is fully automated.

** Git Flow - the nitty gritty

git flow establishes a structure that is time-proven and boosts
productivity and "incremental" merges instead of putting off merging
until the final moments on a Friday.

git flow init and the developer work by this process:

- git-flow: creates main/master as the release branch
- git-flow: creates develop as the development trunk
- git-flow/developer: creates "feature" branches for a specific task.
- developer: works in "feature" and merges develop changes from the team with "pulls"
- developer: when work is done, "squashes" the "feature" and merges into "develop"
- developer: when "develop" is ready for testing, they make a "alpha" tag
- developer: when integration begins "beta" tags are created.
- developer: when integration is complete a "release" merge into "main" is done.

All of the developer tasks are not done manually, instead they are done with
either PythonSh commands or git flow commands.

** PythonSh Version Control Feature Summary

#+BEGIN_SRC bash
track = set upstream tracking
tag-alpha = create alpha tag
tag-beta = create beta tag
info = show branches, tracking, and status
verify = verify commit cryptographic signatures
status = show status of repository and all sub-modules
fetch = fetch main, develop, and current branch
pull = pull current branch no ff
staged = show staged changes
merges = show merges only
releases = show releases (tags)
history = show commit history
summary = show diffstat between feature and develop or last release and develop
delta = show diff between feature and develop or last release and develop
ahead = show log of commits in branch but not in parent
behind = show log of commit in parent but not branch

release-report = generate a report of changes since last release
status-report = generate a report of changes ahead of the trunk

graph = show history between feature and develop or last release and develop
upstream = fetch upstream and show changes not yet merged
sync = merge from the root branch commits not in this branch no ff
#+END_SRC

** PythonSh Version Control in-depth

Let's look at the version control capabilities in-depth and see what
developers could do if they intensively studied git and git-flow.

*** status

This is a example of using status:

#+BEGIN_SRC bash
<devil> [pastepipe_dev] pastepipe:develop(*) -> status
On branch develop
Your branch is up to date with 'origin/develop'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
  modified:   Pipfile.lock
  modified:   pyproject.toml

Untracked files:
  (use "git add <file>..." to include in what will be committed)
  dist/
  src/pastepipe.egg-info/

no changes added to commit (use "git add" and/or "git commit -a")
<devil> [pastepipe_dev] pastepipe:develop(*) ->
#+END_SRC

*** info

#+BEGIN_SRC bash
<devil> [pastepipe_dev] pastepipe:develop(*) -> ./py.sh info
,*  develop 41eb5d6 [origin/develop] (fix) update the pythonsh infrastructure
  main    384168c [origin/main] (pull) pull latest pythonsh
<devil> [pastepipe_dev] pastepipe:develop(*) ->
#+END_SRC

py.sh info shows the stauts of the branches. this is a very handy
command.

*** track

#+BEGIN_SRC bash
track <1> <2>  = set upstream tracking 1=remote 2=branch
#+END_SRC

sometimes you need to set the upstream for a branch. track makes this easy.

*** fetch & pull

#+BEGIN_SRC bash
fetch      = fetch main, develop, and current branch
pull       = pull to current branch no ff
#+END_SRC

fetch  retrieves the commits from upstream but does not merge
them. pull is basically fetch + merge.

*** staged

#+BEGIN_SRC bash
staged     = show staged changes
#+END_SRC

show staged changes. Note that git diff
showing the unstaged changes is a shell alias.

*** Advanced View

#+BEGIN_SRC bash
merges = show merges only
history = show commit history
summary = show diffstat of branch to trunk or trunk to release.
delta = show diff of branch to trunk or trunk to release
log = show log of branch to trunk or trunk to release
graph = show history graph of branch to trunk or trunk to release
upstream = show upstream changes that havent been merged yet
#+END_SRC

The most powerful feature is "agains the parent". What this means is
that pythonsh detects if it's on a feature branch, the develop trunk,
or the main trunk.

- if on a feature branch it's a diff from develop -> feature
- if on the develop branch it's a diff from main -> develop
- if on main it's a diff from the last tag -> main

This intelligence means a single command can be used in three
different contexts with no additional arguments.

#+BEGIN_SRC bash
sync       = merge from the root branch commits not in this branch no ff
#+END_SRC

sync is a tool to pull changes from the parent into the current branch. This
is used for when development work on the develop trunk needs to be merged
into the feature branch.

*** tagging

#+BEGIN_SRC bash
tag-alpha  <feat> <msg> = create an alpha tag on the feature branch
tag-beta   <feat> <msg> = create a beta tag on the trunk
#+END_SRC

tagging is important for making a file set for alpha or beta
releases. by drawing a line across the repository the entire state of
the repo can be checked out.

* Packaging and Integration

Python packaging can be very difficult because there are many different
systems fragmenting the tool-chain into camps that don't get along.

The Python developers tried to impose some order on the build process.
The PEP 517 standard with pyproject.toml is their attempt to
homogenize the build landscape.

However instead of making things uniform it fanned the flames by
specifying backends as plugins, and duplicated the dependancy
information also in Pipfile.

Now the developer has to keep in sync both Pipfile and pyproject.toml.
This is arguably almost worse than before.

PythonSh uses the PEP517 build, but instead of maintaining the files
by hand, Pythonsh puts Pipfile fragments in the source modules and
generates both the Pipfile, and pyproject.toml from these fragments.

This means that the files will always be in sync since they are
generated by the same tool, and from the same sources.

** Virtual Environments

Python package management takes place in virtual environments.
These are directories that have a python built from source
and a set of installed packages.

When you "activate" a virtual environment and your shell
is correctly set you can execute programs, including
python, in that environment.

*** Virtual Environment Stucture

A project has four virtual environments

- dev: for development
- test: for pre-release testing
- build: for building a release
- release: for testing release packages

The build environment is created and destroyed automatically. The
release environment is created as needed.

the "dev" and "test" environments are the commonly used ones. With the
shell setup by py.sh typing

- "switch_dev" = switch to development environment
- "switch_test" = switch to test environment

The most important thing is to focus on with virtual environments
is that dev, test, and release is that they are kept in sync mirroring
places like cloud environments, or on-site environments.

The process for code to bake is: dev -> test -> release

- First dev is a sandbox for developmental code. 
- Test is an environment for integration testing.
- release is a environment for checking that the build works in "prod".

Code is first built in dev. From dev it's promoted to testing to
integrate with other developers. From test it's release tested.  If
there is feedback from release or test it goes back to test.

** Building

Building should be done in an isolated environtment. tox allows
for tests and such to execute in different environments but this
will dissapear as older python versions are phased out. With
virtualenv you can take your python with you so multiple versions
of python isn't a target anymore.

#+BEGIN_SRC bash
./py.sh build
#+END_SRC

This is all it takes to build a package with PythonSh.

* Release

The release process is often the worst of the practices in the
environment. It is common convention to never do a release late in the
week, because there is always a huge hurdle of after-release activity
to hammer the release into shape.

This is absolutely unacceptable. Good programmer's dont forget stuff
in the release or have to patch the release numerous times due to
integration issues, and missing files or code. Good programmers take
extra effort to hit the mark with releases.

Second of all it should be an absolute rule that enough is recorded to
make it possible to rebuild a release. If your repository doesn't have
enough information to rebuild, and the situation arises where you need
to, it's like an airbag: you don't need it usually, but when you do,
it's a life saver.

** PythonSh Release Process

PythonSh walk the developer through a automated process to perform
the release.

** Building & Testing

The build for a release can come in two flavors with python.sh:

- Singular packages created by the python build module. 
- The second type is a buildset package which is an
  abbreviation for built set. it's a zip named like a wheel, except it's
  a all the runtime dependencies gathered from the test virtual
  environment.

buildset packages are used when there are private packages in the mix
and we need to be able to install all the dependencies in one shot.

to start the release proccess a release environment is
created.

#+BEGIN_SRC bash
./py.sh mkrelease

switch_release

pipenv install <package>
#+END_SRC

This use of a release virtualenv allows the package to be tested
in an environment that mirrors "prod"

Code takes time bake, and so rushing into a release is not a good
idea. after some time has passed and a few final fixes are made it's
time for the full source release process to start.

** Source Release Procedure

- start: start the release
- verify: not a command, but drop down to a shell to inspect the
  release and fix any missing or incorrect files.
- release: tag, and merge back into main and develop

#+BEGIN_SRC bash
check  = fetch main, develop from origin and show log of any pending changes
start  = initiate an EDITOR session to update VERSION in python.sh, reload config,
         sanapshot Pipfile if present, and start a git flow release with VERSION

         for the first time pass version as an argument: "./py.sh start 0.1.0"

release = execute git flow release finish with VERSION
upload  = push main and develop branches and tags to remote
#+END_SRC

- checks are ran to make sure the repository and virtual environment
  are ready for a release
- the release is created with git flow
- Pipfile is generated and locked
- The Pipfile, Pipfile.lock, and python.sh are copied into a release/
  directory with the version of the release appended
- all files added or generated are added to git
- an automatic git commit is performed

Then the release drops down to a shell so the developer can inspect
the release. On this release branch the developer can fix up any
missing or incorrect bits.

- Finally the developer issues:

#+BEGIN_SRC bash
./py.sh release
#+END_SRC

Git flow automatically finalizes the release:

- The release is merged back into main - the release trunk
- The release is merged back into develop - the development trunk
- a tag is created starting with "release"

The developer would insert the release-report into the release trunk
merge producing a easy to understand set of release notes describing
all the ingredients baked into the release.

#+BEGIN_SRC bash
./py.sh upload
#+END_SRC

- upload: the upload command pushes the main and development trunks
  upstream.

#+LATEX: \appendix

* Appendix

** python.sh

python.sh is the master file for pythonsh.
It contains all the variables needed to
generate python files.

The idea is that there is one master file,
and all the other files are generated from
it so they are all synchronized.

Unfortunately python has numerous redundancies
so syncing them up is key, and best done
with a single master file.

Here is an example from pythonsh itself:

#+BEGIN_SRC bash
,# pythonsh configuration file
VERSION=0.14.0

PACKAGES=pyutils
SOURCE=.

BUILD_NAME=pythonsh

DOCKER_VERSION="0.1.0"

VIRTUAL_PREFIX='pythonsh'
PYTHON_VERSION='3.12'
#+END_SRC

- VERSION = the version of the repository
- PACKAGES = packages that comprise the project
- SOURCE = the directory containing the package sources. it is typically: "src/"
- BUILD_NAME = the name of the built packages
- VIRTUAL_PREFIX = the prefix for the virtualenvs. pythonsh = "pythonsh_dev" etc...
- PYTHON_VERSION = what python version to install/use
 
From this the following packages are generated:

- pyproject.toml = PEP517 build template. contains build system directives and runtime dependencies
- Pipfile = Dependency management. sections for repositories, dependencies, and other variables.

** Virtual Environment Creation

When the virtual environments are created the latest possible PYTHON
matching the PYTHON_VERSION is installed. This is done
automatically. If a interpreter has already been built for that
version it is re-used.

Then the virtualenvs are created by

#+BEGIN_SRC bash
./py.sh project-virtual
#+END_SRC

This creates VIRTUAL_PREFIX-{dev,test}

Then the environment is bootstrapped.

** boostrap

#+BEGIN_SRC bash
./py.sh bootstrap
#+END_SRC

There are many steps to a bootstrap

- The pip command is upgraded, pipenv is installed
- ./py.sh minimal which installs only the packages needed by pythonsh itself
- then a search is made of the source directories for .pypi and Pipfile

This is unique to pythonsh. Normally all Pipfile instances are
singluar and at the root of the tree. However pythonsh is built to
find fragments of Pipfile in source directories, and installed
packages.

The .pypi fils define repositories. Typically for open-source projects
only the central pypi repository is used. However for commercial
projects private artifact repositories are used as well.

- now all the .pypi repos and fragements are merged by the highest version

This merging process reduces tangled dependencies by syncing all the
dependencies at the teir 1 packages.

- The root Pipfile is written with the packages are installed.

- A second pass then searches installed packages for fragments and merges those

This second pass allows us to gather Pipfile fragments from installed
packages from the first pass.

- Now the final install takes place with all the teir-1 and teir-2 dependencies synced.

- at both stages vulnerability checks are performed.

- finally pyproject.toml is written for the PEP517 build "build" module.

The pyproject.toml build file contains all of the information needed to build
the package.

It is not currently possible to specifiy additional repositories with
a setuptools backend in pyproject.toml. This means that if there are
private repositories it's not possible to specify the dependencies.

When all of the packages are on pypi a dependencies list will be written
to pyproject.toml. If there are other repositories dependencies will be
supressed but the rest of the file will be written.

This is the boostrap process. The end result is that the active
virtualenv will contain a highly homogenous package set for the
project.

Actually pyproject.toml is not generated until a package build
is performed but the two files: Pipfile and pyproject.toml share
a context.

** Python commands

#+BEGIN_SRC bash
test    = run pytests
python  = execute python in pyenv
repl    = execute ptpython in pyenv
run     = run a command in pyenv
#+END_SRC

The python commands include all of the basic functionality for python
development.

- test = run unit tests
- python = run a python file
- repl = run a ptpython interactive repl
- run = run a command in the virtual environment

** Package commands

#+BEGIN_SRC bash
versions   = display the versions of python and installed packages
locked     = update from lockfile
all        = update pip and pipenv install dependencies and dev, lock and check
update     = update installed packages, lock and check
remove     = uninstall the listed packages
list       = list installed packages
#+END_SRC

- versions = display the versions of installed packages
- locked = update the lockfile, which is a file of pinned packages
- all = update pip, pipenv, and install packages including dev packages
- update = update packages to the latest possible versions
- remove = remove a package
- list = show all installed packages in a dependency graph

#+print_bibliography:
